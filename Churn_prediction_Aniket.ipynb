{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>event1</th>\n",
       "      <th>MOB(yrs)</th>\n",
       "      <th>age</th>\n",
       "      <th>TOP_PERSO</th>\n",
       "      <th>TOP_IMMO</th>\n",
       "      <th>TOP_CAV</th>\n",
       "      <th>TOP_GSM</th>\n",
       "      <th>TOP_ASSV</th>\n",
       "      <th>TOP_CB_VISA</th>\n",
       "      <th>...</th>\n",
       "      <th>MONS_INLIM_CARS</th>\n",
       "      <th>MONS_INLIM_DAV</th>\n",
       "      <th>MONS_INLIM_PORT</th>\n",
       "      <th>MONS_INLIM_NB_PROD</th>\n",
       "      <th>MONS_INLIM_CRFLOW</th>\n",
       "      <th>MONS_INLIM_DRFLOW</th>\n",
       "      <th>MONS_INLIM_PROCL</th>\n",
       "      <th>MONS_INLIM_SERCL</th>\n",
       "      <th>Change_cr</th>\n",
       "      <th>Change_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NON_EVENT</td>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>50.802139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NON_EVENT</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>21.568627</td>\n",
       "      <td>-15.175097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NON_EVENT</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-8.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NON_EVENT</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-10.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NON_EVENT</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.233766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event     event1  MOB(yrs)  age  TOP_PERSO  TOP_IMMO  TOP_CAV  TOP_GSM  \\\n",
       "0      0  NON_EVENT        13   63          0         0        1        0   \n",
       "1      0  NON_EVENT         2   36          0         0        1        0   \n",
       "2      0  NON_EVENT        19   49          0         0        1        0   \n",
       "3      0  NON_EVENT         2   57          0         0        1        0   \n",
       "4      0  NON_EVENT        16   59          0         0        1        0   \n",
       "\n",
       "   TOP_ASSV  TOP_CB_VISA  ...  MONS_INLIM_CARS  MONS_INLIM_DAV  \\\n",
       "0         1            0  ...                0               0   \n",
       "1         1            1  ...               12              11   \n",
       "2         1            1  ...               12              12   \n",
       "3         0            1  ...               12              12   \n",
       "4         0            1  ...                0              12   \n",
       "\n",
       "   MONS_INLIM_PORT  MONS_INLIM_NB_PROD  MONS_INLIM_CRFLOW  MONS_INLIM_DRFLOW  \\\n",
       "0                0                  12                  7                 12   \n",
       "1                0                  12                 11                 11   \n",
       "2                0                  12                 12                 12   \n",
       "3                0                  12                 12                 11   \n",
       "4                0                  11                 12                 11   \n",
       "\n",
       "   MONS_INLIM_PROCL  MONS_INLIM_SERCL   Change_cr  Change_db  \n",
       "0                12                12 -100.000000  50.802139  \n",
       "1                12                12   21.568627 -15.175097  \n",
       "2                12                12    6.666667  -8.387097  \n",
       "3                12                12  -60.000000 -10.576923  \n",
       "4                 2                12    0.000000 -66.233766  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "features = pd.read_csv(\"trainsample_SEG5_V1.csv\")\n",
    "features_gb = pd.read_csv(\"trainsample_SEG5_V1.csv\")\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our features is: (18898, 71)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of our features is:', features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>MOB(yrs)</th>\n",
       "      <th>age</th>\n",
       "      <th>TOP_PERSO</th>\n",
       "      <th>TOP_IMMO</th>\n",
       "      <th>TOP_CAV</th>\n",
       "      <th>TOP_GSM</th>\n",
       "      <th>TOP_ASSV</th>\n",
       "      <th>TOP_CB_VISA</th>\n",
       "      <th>TOP_CB_BUSI</th>\n",
       "      <th>...</th>\n",
       "      <th>MONS_INLIM_CARS</th>\n",
       "      <th>MONS_INLIM_DAV</th>\n",
       "      <th>MONS_INLIM_PORT</th>\n",
       "      <th>MONS_INLIM_NB_PROD</th>\n",
       "      <th>MONS_INLIM_CRFLOW</th>\n",
       "      <th>MONS_INLIM_DRFLOW</th>\n",
       "      <th>MONS_INLIM_PROCL</th>\n",
       "      <th>MONS_INLIM_SERCL</th>\n",
       "      <th>Change_cr</th>\n",
       "      <th>Change_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18898.00000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.00000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "      <td>18898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.06334</td>\n",
       "      <td>10.525188</td>\n",
       "      <td>39.922214</td>\n",
       "      <td>0.091438</td>\n",
       "      <td>0.017303</td>\n",
       "      <td>0.99910</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.275320</td>\n",
       "      <td>0.659170</td>\n",
       "      <td>0.042015</td>\n",
       "      <td>...</td>\n",
       "      <td>5.742142</td>\n",
       "      <td>9.572124</td>\n",
       "      <td>1.304265</td>\n",
       "      <td>7.490528</td>\n",
       "      <td>10.567415</td>\n",
       "      <td>10.540586</td>\n",
       "      <td>6.295904</td>\n",
       "      <td>10.710393</td>\n",
       "      <td>-5.712331</td>\n",
       "      <td>-8.583344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.24358</td>\n",
       "      <td>5.771598</td>\n",
       "      <td>17.665819</td>\n",
       "      <td>0.288239</td>\n",
       "      <td>0.130403</td>\n",
       "      <td>0.02998</td>\n",
       "      <td>0.022998</td>\n",
       "      <td>0.446687</td>\n",
       "      <td>0.474001</td>\n",
       "      <td>0.200629</td>\n",
       "      <td>...</td>\n",
       "      <td>5.031133</td>\n",
       "      <td>3.192789</td>\n",
       "      <td>3.542726</td>\n",
       "      <td>4.829850</td>\n",
       "      <td>2.082805</td>\n",
       "      <td>2.090904</td>\n",
       "      <td>5.065906</td>\n",
       "      <td>3.393275</td>\n",
       "      <td>87.494017</td>\n",
       "      <td>201.427554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6700.000000</td>\n",
       "      <td>-18100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-15.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>27.768817</td>\n",
       "      <td>16.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             event      MOB(yrs)           age     TOP_PERSO      TOP_IMMO  \\\n",
       "count  18898.00000  18898.000000  18898.000000  18898.000000  18898.000000   \n",
       "mean       0.06334     10.525188     39.922214      0.091438      0.017303   \n",
       "std        0.24358      5.771598     17.665819      0.288239      0.130403   \n",
       "min        0.00000      1.000000     10.000000      0.000000      0.000000   \n",
       "25%        0.00000      6.000000     25.000000      0.000000      0.000000   \n",
       "50%        0.00000     11.000000     40.000000      0.000000      0.000000   \n",
       "75%        0.00000     16.000000     55.000000      0.000000      0.000000   \n",
       "max        1.00000     20.000000     70.000000      1.000000      1.000000   \n",
       "\n",
       "           TOP_CAV       TOP_GSM      TOP_ASSV   TOP_CB_VISA   TOP_CB_BUSI  \\\n",
       "count  18898.00000  18898.000000  18898.000000  18898.000000  18898.000000   \n",
       "mean       0.99910      0.000529      0.275320      0.659170      0.042015   \n",
       "std        0.02998      0.022998      0.446687      0.474001      0.200629   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.00000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        1.00000      0.000000      1.000000      1.000000      0.000000   \n",
       "max        1.00000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...  MONS_INLIM_CARS  MONS_INLIM_DAV  MONS_INLIM_PORT  \\\n",
       "count  ...     18898.000000    18898.000000     18898.000000   \n",
       "mean   ...         5.742142        9.572124         1.304265   \n",
       "std    ...         5.031133        3.192789         3.542726   \n",
       "min    ...         0.000000        0.000000         0.000000   \n",
       "25%    ...         0.000000        8.000000         0.000000   \n",
       "50%    ...         5.000000       11.000000         0.000000   \n",
       "75%    ...        12.000000       12.000000         0.000000   \n",
       "max    ...        12.000000       12.000000        12.000000   \n",
       "\n",
       "       MONS_INLIM_NB_PROD  MONS_INLIM_CRFLOW  MONS_INLIM_DRFLOW  \\\n",
       "count        18898.000000       18898.000000       18898.000000   \n",
       "mean             7.490528          10.567415          10.540586   \n",
       "std              4.829850           2.082805           2.090904   \n",
       "min              0.000000           0.000000           0.000000   \n",
       "25%              2.000000          10.000000          10.000000   \n",
       "50%             10.000000          11.000000          11.000000   \n",
       "75%             12.000000          12.000000          12.000000   \n",
       "max             12.000000          12.000000          12.000000   \n",
       "\n",
       "       MONS_INLIM_PROCL  MONS_INLIM_SERCL     Change_cr     Change_db  \n",
       "count      18898.000000      18898.000000  18898.000000  18898.000000  \n",
       "mean           6.295904         10.710393     -5.712331     -8.583344  \n",
       "std            5.065906          3.393275     87.494017    201.427554  \n",
       "min            0.000000          0.000000  -6700.000000 -18100.000000  \n",
       "25%            0.000000         12.000000    -25.000000    -15.858300  \n",
       "50%            7.000000         12.000000      3.448276      0.000000  \n",
       "75%           12.000000         12.000000     27.768817     16.129032  \n",
       "max           12.000000         12.000000    100.000000    100.000000  \n",
       "\n",
       "[8 rows x 70 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = np.array(features['event'])\n",
    "\n",
    "# Remove the labels from the features , axis 1 refers to the columns\n",
    "features= features.drop(['event', 'event1'], axis = 1)\n",
    "#features= features.drop(['BAD'], axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "features = np.array(features)\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (15118, 69)\n",
      "Training Labels Shape: (15118,)\n",
      "Testing Features Shape: (3780, 69)\n",
      "Testing Labels Shape: (3780,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3528   17]\n",
      " [ 211   24]]\n",
      "Accuracy: 0.9396825396825397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter = 500)\n",
    "lr.fit(train_features, train_labels)\n",
    "#print(lr.coef_)\n",
    "#print(lr.intercept_)\n",
    "\n",
    "y_pred=lr.predict(test_features)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(test_labels,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(test_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 500,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'warn',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest ###\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# n_estimators = number of trees in the foreset -> more trees less variance but high computation\n",
    "# max_features = max number of features considered for splitting a node\n",
    "# max_depth = max number of levels in each decision tree -> less depth more bias\n",
    "# min_samples_split = min number of data points placed in a node before the node is split\n",
    "# min_samples_leaf = min number of data points allowed in a leaf node -> less means less bias more variance\n",
    "# bootstrap = method for sampling data points (with or without replacement)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=1000, random_state=42,max_features='sqrt')\n",
    "rf.fit(train_features, train_labels)\n",
    "predictions = rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 1000,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If “auto”, then max_features=sqrt(n_features).\n",
    "If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "If “log2”, then max_features=log2(n_features).\n",
    "If None, then max_features=n_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3515   30]\n",
      " [  81  154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3545\n",
      "           1       0.84      0.66      0.74       235\n",
      "\n",
      "    accuracy                           0.97      3780\n",
      "   macro avg       0.91      0.82      0.86      3780\n",
      "weighted avg       0.97      0.97      0.97      3780\n",
      "\n",
      "0.9706349206349206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_labels,predictions.round()))\n",
    "print(classification_report(test_labels,predictions.round()))\n",
    "print(accuracy_score(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3516   29]\n",
      " [  93  142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3545\n",
      "           1       0.83      0.60      0.70       235\n",
      "\n",
      "    accuracy                           0.97      3780\n",
      "   macro avg       0.90      0.80      0.84      3780\n",
      "weighted avg       0.97      0.97      0.97      3780\n",
      "\n",
      "0.9677248677248678\n"
     ]
    }
   ],
   "source": [
    "### Random Forest ###\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# n_estimators = number of trees in the foreset -> more trees less variance but high computation\n",
    "# max_features = max number of features considered for splitting a node\n",
    "# max_depth = max number of levels in each decision tree -> less depth more bias\n",
    "# min_samples_split = min number of data points placed in a node before the node is split\n",
    "# min_samples_leaf = min number of data points allowed in a leaf node -> less means less bias more variance\n",
    "# bootstrap = method for sampling data points (with or without replacement)\n",
    "\n",
    "rf2 = RandomForestRegressor(n_estimators=1000, random_state=42,max_features='log2')\n",
    "rf2.fit(train_features, train_labels)\n",
    "predictions = rf2.predict(test_features)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_labels,predictions.round()))\n",
    "print(classification_report(test_labels,predictions.round()))\n",
    "print(accuracy_score(test_labels, predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Ratio_crdt_trnovr_0_6mois Importance: 0.08\n",
      "Variable: Ratio_dbt_bal_0_12mois Importance: 0.08\n",
      "Variable: top_clot_cav12       Importance: 0.07\n",
      "Variable: Ratio_dbt_bal_0_6mois Importance: 0.07\n",
      "Variable: Ratio_dbt_trnovr_0_12mois Importance: 0.05\n",
      "Variable: Ratio_dbt_trnovr_0_6mois Importance: 0.04\n",
      "Variable: change_nb_prod       Importance: 0.04\n",
      "Variable: Avg_Crdt_trnovr_6mois Importance: 0.03\n",
      "Variable: Ratio_crdt_trnovr_6_12mois Importance: 0.03\n",
      "Variable: Ratio_dbt_bal_6_12mois Importance: 0.03\n",
      "Variable: MONS_INLIM_NB_PROD   Importance: 0.03\n",
      "Variable: MONS_INLIM_SERCL     Importance: 0.03\n",
      "Variable: Avg_Dbt_Bal_6mois    Importance: 0.02\n",
      "Variable: Avg_Dbt_Bal_12mois   Importance: 0.02\n",
      "Variable: Avg_Crdt_trnovr_12mois Importance: 0.02\n",
      "Variable: Avg_Dbt_trnovr_6mois Importance: 0.02\n",
      "Variable: Avg_Dbt_trnovr_12mois Importance: 0.02\n",
      "Variable: Avg_Savngs_Bal_12mois Importance: 0.02\n",
      "Variable: Ratio_dbt_trnovr_6_12mois Importance: 0.02\n",
      "Variable: Ratio_Savngs_bal_0_6mois Importance: 0.02\n",
      "Variable: Ratio_Savngs_bal_0_12mois Importance: 0.02\n",
      "Variable: Ratio_Savngs_bal_6_12mois Importance: 0.02\n",
      "Variable: mt_rvnu              Importance: 0.02\n",
      "Variable: Change_TRB           Importance: 0.02\n",
      "Variable: Change_cr            Importance: 0.02\n",
      "Variable: Change_db            Importance: 0.02\n",
      "Variable: MOB(yrs)             Importance: 0.01\n",
      "Variable: age                  Importance: 0.01\n",
      "Variable: Avg_Savngs_Bal_6mois Importance: 0.01\n",
      "Variable: MONS_INLIM_TRB       Importance: 0.01\n",
      "Variable: MONS_INLIM_CARS      Importance: 0.01\n",
      "Variable: MONS_INLIM_DAV       Importance: 0.01\n",
      "Variable: MONS_INLIM_CRFLOW    Importance: 0.01\n",
      "Variable: MONS_INLIM_DRFLOW    Importance: 0.01\n",
      "Variable: MONS_INLIM_PROCL     Importance: 0.01\n",
      "Variable: TOP_PERSO            Importance: 0.0\n",
      "Variable: TOP_IMMO             Importance: 0.0\n",
      "Variable: TOP_CAV              Importance: 0.0\n",
      "Variable: TOP_GSM              Importance: 0.0\n",
      "Variable: TOP_ASSV             Importance: 0.0\n",
      "Variable: TOP_CB_VISA          Importance: 0.0\n",
      "Variable: TOP_CB_BUSI          Importance: 0.0\n",
      "Variable: TOP_CB_PREMIER       Importance: 0.0\n",
      "Variable: TOP_CB_INFI          Importance: 0.0\n",
      "Variable: TOP_CB_MASTER        Importance: 0.0\n",
      "Variable: TOP_CONV_M_1         Importance: 0.0\n",
      "Variable: top_clot_pea12       Importance: 0.0\n",
      "Variable: top_clot_IMMO12      Importance: 0.0\n",
      "Variable: top_clot_PERSO12     Importance: 0.0\n",
      "Variable: top_staff            Importance: 0.0\n",
      "Variable: TOP_PEA              Importance: 0.0\n",
      "Variable: TOP_TITRE            Importance: 0.0\n",
      "Variable: TOP_INV              Importance: 0.0\n",
      "Variable: top_cars             Importance: 0.0\n",
      "Variable: top_carte            Importance: 0.0\n",
      "Variable: TOP_PAssport         Importance: 0.0\n",
      "Variable: Contact_3mois        Importance: 0.0\n",
      "Variable: Contact_6mois        Importance: 0.0\n",
      "Variable: Contact_9mois        Importance: 0.0\n",
      "Variable: Contact_12mois       Importance: 0.0\n",
      "Variable: Avg_Wealth_Bal_6mois Importance: 0.0\n",
      "Variable: Avg_Wealth_Bal_12mois Importance: 0.0\n",
      "Variable: NB_PE_ME             Importance: 0.0\n",
      "Variable: mt_dbloc_cons_rep    Importance: 0.0\n",
      "Variable: mt_capir_cons_rep    Importance: 0.0\n",
      "Variable: mt_dbloc_immo_rep    Importance: 0.0\n",
      "Variable: mt_capir_immo_rep    Importance: 0.0\n",
      "Variable: MONS_INLIM_ASV       Importance: 0.0\n",
      "Variable: MONS_INLIM_PORT      Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOB(yrs)',\n",
       " 'age',\n",
       " 'TOP_PERSO',\n",
       " 'TOP_IMMO',\n",
       " 'TOP_CAV',\n",
       " 'TOP_GSM',\n",
       " 'TOP_ASSV',\n",
       " 'TOP_CB_VISA',\n",
       " 'TOP_CB_BUSI',\n",
       " 'TOP_CB_PREMIER',\n",
       " 'TOP_CB_INFI',\n",
       " 'TOP_CB_MASTER',\n",
       " 'TOP_CONV_M_1',\n",
       " 'top_clot_cav12',\n",
       " 'top_clot_pea12',\n",
       " 'top_clot_IMMO12',\n",
       " 'top_clot_PERSO12',\n",
       " 'top_staff',\n",
       " 'TOP_PEA',\n",
       " 'TOP_TITRE',\n",
       " 'TOP_INV',\n",
       " 'top_cars',\n",
       " 'top_carte',\n",
       " 'TOP_PAssport',\n",
       " 'Contact_3mois',\n",
       " 'Contact_6mois',\n",
       " 'Contact_9mois',\n",
       " 'Contact_12mois',\n",
       " 'Avg_Dbt_Bal_6mois',\n",
       " 'Avg_Dbt_Bal_12mois',\n",
       " 'Avg_Crdt_trnovr_6mois',\n",
       " 'Avg_Crdt_trnovr_12mois',\n",
       " 'Avg_Dbt_trnovr_6mois',\n",
       " 'Avg_Dbt_trnovr_12mois',\n",
       " 'Avg_Savngs_Bal_6mois',\n",
       " 'Avg_Savngs_Bal_12mois',\n",
       " 'Ratio_crdt_trnovr_0_6mois',\n",
       " 'Ratio_crdt_trnovr_6_12mois',\n",
       " 'Ratio_dbt_trnovr_0_6mois',\n",
       " 'Ratio_dbt_trnovr_0_12mois',\n",
       " 'Ratio_dbt_trnovr_6_12mois',\n",
       " 'Ratio_dbt_bal_0_6mois',\n",
       " 'Ratio_dbt_bal_0_12mois',\n",
       " 'Ratio_dbt_bal_6_12mois',\n",
       " 'Ratio_Savngs_bal_0_6mois',\n",
       " 'Ratio_Savngs_bal_0_12mois',\n",
       " 'Ratio_Savngs_bal_6_12mois',\n",
       " 'Avg_Wealth_Bal_6mois',\n",
       " 'Avg_Wealth_Bal_12mois',\n",
       " 'NB_PE_ME',\n",
       " 'mt_rvnu',\n",
       " 'mt_dbloc_cons_rep',\n",
       " 'mt_capir_cons_rep',\n",
       " 'mt_dbloc_immo_rep',\n",
       " 'mt_capir_immo_rep',\n",
       " 'Change_TRB',\n",
       " 'change_nb_prod',\n",
       " 'MONS_INLIM_TRB',\n",
       " 'MONS_INLIM_ASV',\n",
       " 'MONS_INLIM_CARS',\n",
       " 'MONS_INLIM_DAV',\n",
       " 'MONS_INLIM_PORT',\n",
       " 'MONS_INLIM_NB_PROD',\n",
       " 'MONS_INLIM_CRFLOW',\n",
       " 'MONS_INLIM_DRFLOW',\n",
       " 'MONS_INLIM_PROCL',\n",
       " 'MONS_INLIM_SERCL',\n",
       " 'Change_cr',\n",
       " 'Change_db']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new = features.drop([\"event\", \"event1\", \"TOP_PERSO\",\n",
    " \"TOP_IMMO\", \"TOP_CAV\", \"TOP_GSM\"              \n",
    " ,\"TOP_ASSV\"             \n",
    ",\"TOP_CB_VISA\"          \n",
    ",\"TOP_CB_BUSI\"          \n",
    ",\"TOP_CB_PREMIER\"       \n",
    " ,\"TOP_CB_INFI\"          \n",
    " ,\"TOP_CB_MASTER\"        \n",
    ", \"TOP_CONV_M_1\"         \n",
    ", \"top_clot_pea12\"       \n",
    " ,\"top_clot_IMMO12\"      \n",
    " ,\"top_clot_PERSO12\"     \n",
    ", \"top_staff\"            \n",
    ", \"TOP_PEA\"             \n",
    ", \"TOP_TITRE\"            \n",
    ", \"TOP_INV\"             \n",
    ", \"top_cars\"             \n",
    ", \"top_carte\"          \n",
    ", \"TOP_PAssport\"         \n",
    ", \"Contact_3mois\"      \n",
    " ,\"Contact_6mois\"        \n",
    ", \"Contact_9mois\"        \n",
    ", \"Contact_12mois\"      \n",
    " ,\"Avg_Wealth_Bal_6mois\"\n",
    ", \"Avg_Wealth_Bal_12mois\" \n",
    " ,\"NB_PE_ME\"             \n",
    " ,\"mt_dbloc_cons_rep\"    \n",
    ", \"mt_capir_cons_rep\"    \n",
    ", \"mt_dbloc_immo_rep\"    \n",
    ", \"mt_capir_immo_rep\"    \n",
    " ,\"MONS_INLIM_ASV\", \"MONS_INLIM_PORT\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_new, test_features_new, train_labels_new, test_labels_new = train_test_split(features_new, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3515   30]\n",
      " [  73  162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3545\n",
      "           1       0.84      0.69      0.76       235\n",
      "\n",
      "    accuracy                           0.97      3780\n",
      "   macro avg       0.91      0.84      0.87      3780\n",
      "weighted avg       0.97      0.97      0.97      3780\n",
      "\n",
      "0.9727513227513227\n"
     ]
    }
   ],
   "source": [
    "### Random Forest ###\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# n_estimators = number of trees in the foreset -> more trees less variance but high computation\n",
    "# max_features = max number of features considered for splitting a node\n",
    "# max_depth = max number of levels in each decision tree -> less depth more bias\n",
    "# min_samples_split = min number of data points placed in a node before the node is split\n",
    "# min_samples_leaf = min number of data points allowed in a leaf node -> less means less bias more variance\n",
    "# bootstrap = method for sampling data points (with or without replacement)\n",
    "\n",
    "rf3 = RandomForestRegressor(n_estimators=1000, random_state=42,max_features='sqrt')\n",
    "rf3.fit(train_features_new, train_labels_new)\n",
    "predictions_new = rf3.predict(test_features_new)\n",
    "print(confusion_matrix(test_labels_new,predictions_new.round()))\n",
    "print(classification_report(test_labels_new,predictions_new.round()))\n",
    "print(accuracy_score(test_labels_new, predictions_new.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### GBM #######\n",
    "\n",
    "target = 'event'\n",
    "features_gb= features_gb.drop([\"event1\"], axis =1)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import metrics\n",
    "\n",
    "# max_features = max number of features considered for splitting a node\n",
    "# max_depth = max number of levels in each decision tree -> less depth more bias\n",
    "# min_samples_leaf = min number of data points allowed in a leaf node -> less means less bias more variance\n",
    "#learning_rate = The learning parameter controls the magnitude of this change in the estimates -> lower implies less variance and high computation (no of trees to converge increases)\n",
    "#n_estimators = The number of sequential trees to be modeled -> more tress more robust model using a perfect learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>MOB(yrs)</th>\n",
       "      <th>age</th>\n",
       "      <th>TOP_PERSO</th>\n",
       "      <th>TOP_IMMO</th>\n",
       "      <th>TOP_CAV</th>\n",
       "      <th>TOP_GSM</th>\n",
       "      <th>TOP_ASSV</th>\n",
       "      <th>TOP_CB_VISA</th>\n",
       "      <th>TOP_CB_BUSI</th>\n",
       "      <th>...</th>\n",
       "      <th>MONS_INLIM_CARS</th>\n",
       "      <th>MONS_INLIM_DAV</th>\n",
       "      <th>MONS_INLIM_PORT</th>\n",
       "      <th>MONS_INLIM_NB_PROD</th>\n",
       "      <th>MONS_INLIM_CRFLOW</th>\n",
       "      <th>MONS_INLIM_DRFLOW</th>\n",
       "      <th>MONS_INLIM_PROCL</th>\n",
       "      <th>MONS_INLIM_SERCL</th>\n",
       "      <th>Change_cr</th>\n",
       "      <th>Change_db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>50.802139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>21.568627</td>\n",
       "      <td>-15.175097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-8.387097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-10.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.233766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event  MOB(yrs)  age  TOP_PERSO  TOP_IMMO  TOP_CAV  TOP_GSM  TOP_ASSV  \\\n",
       "0      0        13   63          0         0        1        0         1   \n",
       "1      0         2   36          0         0        1        0         1   \n",
       "2      0        19   49          0         0        1        0         1   \n",
       "3      0         2   57          0         0        1        0         0   \n",
       "4      0        16   59          0         0        1        0         0   \n",
       "\n",
       "   TOP_CB_VISA  TOP_CB_BUSI  ...  MONS_INLIM_CARS  MONS_INLIM_DAV  \\\n",
       "0            0            0  ...                0               0   \n",
       "1            1            0  ...               12              11   \n",
       "2            1            0  ...               12              12   \n",
       "3            1            0  ...               12              12   \n",
       "4            1            0  ...                0              12   \n",
       "\n",
       "   MONS_INLIM_PORT  MONS_INLIM_NB_PROD  MONS_INLIM_CRFLOW  MONS_INLIM_DRFLOW  \\\n",
       "0                0                  12                  7                 12   \n",
       "1                0                  12                 11                 11   \n",
       "2                0                  12                 12                 12   \n",
       "3                0                  12                 12                 11   \n",
       "4                0                  11                 12                 11   \n",
       "\n",
       "   MONS_INLIM_PROCL  MONS_INLIM_SERCL   Change_cr  Change_db  \n",
       "0                12                12 -100.000000  50.802139  \n",
       "1                12                12   21.568627 -15.175097  \n",
       "2                12                12    6.666667  -8.387097  \n",
       "3                12                12  -60.000000 -10.576923  \n",
       "4                 2                12    0.000000 -66.233766  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_gb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modelfit(alg, data,predictors, performCV=False, printFeatureImportance=True):\n",
    "\n",
    "    train,test= train_test_split(data, test_size=0.2, random_state=42)\n",
    "    dtrain=train\n",
    "    dtest=test\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['event'])\n",
    "\n",
    "\n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "\n",
    "    #Predict test set:\n",
    "    dtest_predictions = alg.predict(dtest[predictors])\n",
    "    dtest_predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "\n",
    "    #Perform cross-validation:\n",
    "    #if performCV:\n",
    "    #    cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain['Disbursed'], cv=cv_folds, scoring='roc_auc')\n",
    "\n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['event'].values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['event'], dtrain_predprob))\n",
    "\n",
    "    print (\"\\nModel Report Test\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtest['event'].values, dtest_predictions))\n",
    "    print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(dtest['event'], dtest_predprob))\n",
    "    \n",
    "    #if performCV:\n",
    "    #    print \"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score))\n",
    "\n",
    "    #Print Feature Importance:\n",
    "    if printFeatureImportance:\n",
    "        feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        return(feat_imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9364\n",
      "AUC Score (Train): 0.973177\n",
      "\n",
      "Model Report Test\n",
      "Accuracy : 0.9378\n",
      "AUC Score (Test): 0.970488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ratio_dbt_bal_0_12mois        1.888718e-01\n",
       "Ratio_crdt_trnovr_0_6mois     1.441962e-01\n",
       "Ratio_dbt_bal_0_6mois         1.409134e-01\n",
       "Ratio_dbt_trnovr_0_12mois     9.441394e-02\n",
       "top_clot_cav12                6.888001e-02\n",
       "Ratio_dbt_trnovr_0_6mois      5.443875e-02\n",
       "Ratio_dbt_bal_6_12mois        4.131141e-02\n",
       "Avg_Crdt_trnovr_6mois         3.772024e-02\n",
       "Ratio_crdt_trnovr_6_12mois    3.523364e-02\n",
       "MONS_INLIM_SERCL              3.049663e-02\n",
       "MONS_INLIM_NB_PROD            2.961352e-02\n",
       "change_nb_prod                2.497259e-02\n",
       "Ratio_dbt_trnovr_6_12mois     2.191506e-02\n",
       "Ratio_Savngs_bal_0_12mois     1.491395e-02\n",
       "Avg_Dbt_trnovr_6mois          1.369598e-02\n",
       "Ratio_Savngs_bal_0_6mois      1.248406e-02\n",
       "Ratio_Savngs_bal_6_12mois     8.523248e-03\n",
       "Avg_Dbt_Bal_6mois             7.799634e-03\n",
       "MONS_INLIM_CRFLOW             4.115993e-03\n",
       "mt_capir_immo_rep             3.733834e-03\n",
       "Change_db                     3.463502e-03\n",
       "mt_dbloc_immo_rep             2.849104e-03\n",
       "Avg_Crdt_trnovr_12mois        2.058090e-03\n",
       "Avg_Savngs_Bal_6mois          1.850428e-03\n",
       "Avg_Dbt_trnovr_12mois         1.513306e-03\n",
       "MONS_INLIM_CARS               1.369418e-03\n",
       "Change_TRB                    1.329281e-03\n",
       "MONS_INLIM_DRFLOW             1.273550e-03\n",
       "Change_cr                     1.211001e-03\n",
       "MONS_INLIM_DAV                8.624427e-04\n",
       "                                  ...     \n",
       "Avg_Dbt_Bal_12mois            9.039012e-05\n",
       "top_cars                      6.366710e-05\n",
       "Avg_Wealth_Bal_12mois         4.523145e-05\n",
       "TOP_INV                       1.753189e-05\n",
       "mt_rvnu                       1.325785e-05\n",
       "MONS_INLIM_ASV                1.109521e-05\n",
       "MOB(yrs)                      8.266587e-06\n",
       "age                           6.429238e-06\n",
       "TOP_CONV_M_1                  4.639052e-06\n",
       "Contact_9mois                 2.420824e-06\n",
       "Contact_12mois                2.418763e-06\n",
       "TOP_CB_INFI                   1.319178e-06\n",
       "Contact_3mois                 1.262985e-06\n",
       "Contact_6mois                 7.416710e-07\n",
       "mt_dbloc_cons_rep             6.569957e-07\n",
       "top_clot_PERSO12              4.303617e-07\n",
       "TOP_CB_MASTER                 2.834761e-07\n",
       "TOP_CB_VISA                   0.000000e+00\n",
       "TOP_PERSO                     0.000000e+00\n",
       "NB_PE_ME                      0.000000e+00\n",
       "TOP_CAV                       0.000000e+00\n",
       "TOP_GSM                       0.000000e+00\n",
       "TOP_PAssport                  0.000000e+00\n",
       "TOP_CB_BUSI                   0.000000e+00\n",
       "TOP_CB_PREMIER                0.000000e+00\n",
       "top_clot_IMMO12               0.000000e+00\n",
       "top_staff                     0.000000e+00\n",
       "TOP_PEA                       0.000000e+00\n",
       "TOP_TITRE                     0.000000e+00\n",
       "top_carte                     0.000000e+00\n",
       "Length: 69, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in features_gb.columns if x not in [target]]\n",
    "gbm_tuned_4 = GradientBoostingClassifier(learning_rate=0.005, n_estimators=100,max_depth=9, min_samples_split=1200, min_samples_leaf=60, random_state=42, max_features=7,\n",
    "warm_start=True)\n",
    "modelfit(gbm_tuned_4, features_gb, predictors, performCV=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### XG Boost ######\n",
    "\n",
    "target = 'event'\n",
    "features_xgb= features_gb\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "# Choose a relatively high learning rate. Generally a learning rate of 0.1 works but somewhere between 0.05 to 0.3 should work for different problems. Determine the optimum number of trees for this learning rate. XGBoost has a very useful function called as “cv” which performs cross-validation at each boosting iteration and thus returns the optimum number of trees required.\n",
    "# Tune tree-specific parameters ( max_depth, min_child_weight, gamma, subsample, colsample_bytree) for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here.\n",
    "# Tune regularization parameters (lambda, alpha) for xgboost which can help reduce model complexity and enhance performance.\n",
    "# Lower the learning rate and decide the optimal parameters .\n",
    "\n",
    "\n",
    "# In[112]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50, printFeatureImportance=True):\n",
    "    \n",
    "    train,test= train_test_split(features_xgb, test_size=0.2, random_state=42)\n",
    "    dtrain=train\n",
    "    dtest=test\n",
    "\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain['event'].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['event'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Predict test set:\n",
    "    dtest_predictions = alg.predict(dtest[predictors])\n",
    "    dtest_predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['event'].values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['event'], dtrain_predprob))\n",
    "    \n",
    "    print (\"\\nModel Report Test\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtest['event'].values, dtest_predictions))\n",
    "    print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(dtest['event'], dtest_predprob))\n",
    "\n",
    "#     if printFeatureImportance:\n",
    "#         feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "#         return(feat_imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9724\n",
      "AUC Score (Train): 0.981456\n",
      "\n",
      "Model Report Test\n",
      "Accuracy : 0.9672\n",
      "AUC Score (Test): 0.976455\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in features_xgb.columns if x not in [target]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.005,\n",
    " n_estimators=100,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=42)\n",
    "\n",
    "modelfit(xgb1, features_xgb, predictors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18898, 70)\n",
      "(13228, 69)\n",
      "(5670, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5235   90]\n",
      " [ 137  208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      5325\n",
      "           1       0.70      0.60      0.65       345\n",
      "\n",
      "    accuracy                           0.96      5670\n",
      "   macro avg       0.84      0.79      0.81      5670\n",
      "weighted avg       0.96      0.96      0.96      5670\n",
      "\n",
      "0.9599647266313933\n"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df = features_gb \n",
    "print(df.shape)\n",
    "df.describe().transpose()\n",
    "target_column = ['event']\n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()\n",
    "\n",
    "\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4,4,4), activation='relu', solver='adam', max_iter=1000,learning_rate_init=0.01)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))\n",
    "print(accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18898, 70)\n",
      "(13228, 69)\n",
      "(5670, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5226   99]\n",
      " [ 101  244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      5325\n",
      "           1       0.71      0.71      0.71       345\n",
      "\n",
      "    accuracy                           0.96      5670\n",
      "   macro avg       0.85      0.84      0.85      5670\n",
      "weighted avg       0.96      0.96      0.96      5670\n",
      "\n",
      "0.9647266313932981\n"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df = features_gb \n",
    "print(df.shape)\n",
    "df.describe().transpose()\n",
    "target_column = ['event']\n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()\n",
    "\n",
    "\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4,4,4), activation='logistic', solver='adam', max_iter=1000,learning_rate_init=0.01)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))\n",
    "print(accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18898, 70)\n",
      "(13228, 69)\n",
      "(5670, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5237   88]\n",
      " [ 127  218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      5325\n",
      "           1       0.71      0.63      0.67       345\n",
      "\n",
      "    accuracy                           0.96      5670\n",
      "   macro avg       0.84      0.81      0.82      5670\n",
      "weighted avg       0.96      0.96      0.96      5670\n",
      "\n",
      "0.9620811287477954\n"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df = features_gb \n",
    "print(df.shape)\n",
    "df.describe().transpose()\n",
    "target_column = ['event']\n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()\n",
    "\n",
    "\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4,4,4), activation='tanh', solver='adam', max_iter=1000,learning_rate_init=0.01)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))\n",
    "print(accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18898, 70)\n",
      "(13228, 69)\n",
      "(5670, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5268   57]\n",
      " [ 156  189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5325\n",
      "           1       0.77      0.55      0.64       345\n",
      "\n",
      "    accuracy                           0.96      5670\n",
      "   macro avg       0.87      0.77      0.81      5670\n",
      "weighted avg       0.96      0.96      0.96      5670\n",
      "\n",
      "0.9624338624338624\n"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df = features_gb \n",
    "print(df.shape)\n",
    "df.describe().transpose()\n",
    "target_column = ['event']\n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()\n",
    "\n",
    "\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4,4,4), activation='identity', solver='adam', max_iter=1000,learning_rate_init=0.01)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))\n",
    "print(accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18898, 70)\n",
      "(13228, 69)\n",
      "(5670, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5244   81]\n",
      " [ 174  171]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      5325\n",
      "           1       0.68      0.50      0.57       345\n",
      "\n",
      "    accuracy                           0.96      5670\n",
      "   macro avg       0.82      0.74      0.77      5670\n",
      "weighted avg       0.95      0.96      0.95      5670\n",
      "\n",
      "0.955026455026455\n"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "\n",
    "\n",
    "#trying for sgd with logistic as it performed best#\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df = features_gb \n",
    "print(df.shape)\n",
    "df.describe().transpose()\n",
    "target_column = ['event']\n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()\n",
    "\n",
    "\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4,4,4), activation='logistic', solver='', max_iter=1000,learning_rate_init=0.01)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))\n",
    "print(accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18898, 70)\n",
      "(13228, 69)\n",
      "(5670, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5260   65]\n",
      " [ 153  192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5325\n",
      "           1       0.75      0.56      0.64       345\n",
      "\n",
      "    accuracy                           0.96      5670\n",
      "   macro avg       0.86      0.77      0.81      5670\n",
      "weighted avg       0.96      0.96      0.96      5670\n",
      "\n",
      "0.9615520282186949\n"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "\n",
    "\n",
    "#trying for sgd with logistic as it performed best#\n",
    "\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df = features_gb \n",
    "print(df.shape)\n",
    "df.describe().transpose()\n",
    "target_column = ['event']\n",
    "predictors = list(set(list(df.columns))-set(target_column))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe().transpose()\n",
    "\n",
    "\n",
    "X = df[predictors].values\n",
    "y = df[target_column].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4), activation='logistic', solver='sgd', max_iter=1000,learning_rate_init=0.01)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(confusion_matrix(y_test,predict_test))\n",
    "print(classification_report(y_test,predict_test))\n",
    "print(accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\G\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#### ANN ####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = []\n",
    "neurons = []\n",
    "\n",
    "for i in range(1,31):\n",
    "    neurons.append(i)\n",
    "    df = features_gb \n",
    "    #print(df.shape)\n",
    "    df.describe().transpose()\n",
    "    target_column = ['event']\n",
    "    predictors = list(set(list(df.columns))-set(target_column))\n",
    "    df[predictors] = df[predictors]/df[predictors].max()\n",
    "    df.describe().transpose()\n",
    "\n",
    "\n",
    "    X = df[predictors].values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "    #print(X_train.shape); print(X_test.shape)\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(i), activation='logistic', solver='sgd', max_iter=1000,learning_rate_init=0.01)\n",
    "    mlp.fit(X_train,y_train)\n",
    "\n",
    "    predict_train = mlp.predict(X_train)\n",
    "    predict_test = mlp.predict(X_test)\n",
    "    #from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "    #print(confusion_matrix(y_test,predict_test))\n",
    "    #print(classification_report(y_test,predict_test))\n",
    "    accuracy.append(accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neurons,accuracy)\n",
    "plt.xlabel('neurons')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
